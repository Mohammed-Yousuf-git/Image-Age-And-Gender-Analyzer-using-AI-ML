{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc44946-7c22-4cd5-a38b-51c8821726f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique age group labels and their counts:\n",
      "Class\n",
      "MIDDLE    10804\n",
      "YOUNG      6706\n",
      "OLD        2396\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = \"/Users/usufahmed/Desktop/gender_app/faces/train.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Check unique values and distribution in 'Class' column\n",
    "print(\"Unique age group labels and their counts:\")\n",
    "print(df['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8b699f8-7450-4160-9fb9-175f1a75ec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images found: 19906\n",
      "Sample image filenames: ['9733.jpg', '14147.jpg', '63.jpg', '6400.jpg', '24084.jpg']\n",
      "All images in CSV found in directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_dir = \"/Users/usufahmed/Desktop/gender_app/faces/Train/\"\n",
    "image_files = os.listdir(image_dir)\n",
    "print(f\"Total images found: {len(image_files)}\")\n",
    "print(f\"Sample image filenames: {image_files[:5]}\")\n",
    "\n",
    "# Check for missing files\n",
    "missing_files = df['ID'][~df['ID'].isin(image_files)]\n",
    "if not missing_files.empty:\n",
    "    print(f\"Warning: {len(missing_files)} images listed in CSV but not found in directory.\")\n",
    "    print(\"Sample missing files:\", missing_files.head().tolist())\n",
    "else:\n",
    "    print(\"All images in CSV found in directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6953d088-3805-4841-b5ba-73e0de17f96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 15924\n",
      "Validation samples: 3982\n",
      "\n",
      "Training age group distribution:\n",
      "Class\n",
      "MIDDLE    8643\n",
      "YOUNG     5364\n",
      "OLD       1917\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation age group distribution:\n",
      "Class\n",
      "MIDDLE    2161\n",
      "YOUNG     1342\n",
      "OLD        479\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = \"/Users/usufahmed/Desktop/gender_app/faces/train.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Split dataset into train and validation (80% train, 20% validation)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['Class'], random_state=42)\n",
    "\n",
    "# Print split details\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(\"\\nTraining age group distribution:\")\n",
    "print(train_df['Class'].value_counts())\n",
    "print(\"\\nValidation age group distribution:\")\n",
    "print(val_df['Class'].value_counts())\n",
    "\n",
    "# Save splits (optional, for debugging)\n",
    "train_df.to_csv(\"train_split.csv\", index=False)\n",
    "val_df.to_csv(\"val_split.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13514d16-992d-4fbf-8335-f2a2bb692615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15924 validated image filenames belonging to 3 classes.\n",
      "Found 3982 validated image filenames belonging to 3 classes.\n",
      "Class indices: {'MIDDLE': 0, 'OLD': 1, 'YOUNG': 2}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define image parameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Training data generator with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation data generator (no augmentation, only rescaling)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load training data\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=\"/Users/usufahmed/Desktop/gender_app/faces/Train/\",\n",
    "    x_col='ID',\n",
    "    y_col='Class',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=\"/Users/usufahmed/Desktop/gender_app/faces/Train/\",\n",
    "    x_col='ID',\n",
    "    y_col='Class',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Print class indices\n",
    "print(f\"Class indices: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e68a039-eba8-4a0d-b47b-803647fd31a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset size: 19906\n",
      "Training samples: 15924\n",
      "Validation samples: 3982\n",
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Class indices: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 15924 invalid image filename(s) in x_col=\"ID\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 3982 invalid image filename(s) in x_col=\"ID\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = \"/Users/usufahmed/Desktop/gender_app/faces/train.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Normalize IDs (remove .jpg, lowercase)\n",
    "df['ID'] = df['ID'].str.replace('.jpg', '').str.lower()\n",
    "\n",
    "# Check image directory\n",
    "image_dir = \"/Users/usufahmed/Desktop/gender_app/faces/Train/\"\n",
    "image_files = os.listdir(image_dir) if os.path.exists(image_dir) else []\n",
    "image_bases = [os.path.splitext(f)[0].lower() for f in image_files]\n",
    "\n",
    "# Filter out IDs not found in directory\n",
    "df = df[df['ID'].isin(image_bases)]\n",
    "print(f\"Filtered dataset size: {len(df)}\")\n",
    "\n",
    "# Split dataset\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['Class'], random_state=42)\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "\n",
    "# Define image parameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Training data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load training data (append .jpg to IDs)\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=image_dir,\n",
    "    x_col='ID',\n",
    "    y_col='Class',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    # Ensure .jpg extension is added\n",
    "    x_col_modifier=lambda x: x + '.jpg'\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=image_dir,\n",
    "    x_col='ID',\n",
    "    y_col='Class',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    x_col_modifier=lambda x: x + '.jpg'\n",
    ")\n",
    "\n",
    "# Print class indices\n",
    "print(f\"Class indices: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e80348bb-7abb-49d4-823a-5fb876018cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset size: 19906\n",
      "Training samples: 15924\n",
      "Validation samples: 3982\n",
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Class indices: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 15924 invalid image filename(s) in x_col=\"ID\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 3982 invalid image filename(s) in x_col=\"ID\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = \"/Users/usufahmed/Desktop/gender_app/faces/train.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Normalize IDs (remove .jpg, lowercase, and handle potential extra extensions)\n",
    "df['ID'] = df['ID'].str.replace(r'\\.jpg|\\.jpeg|\\.png', '', regex=True).str.lower().str.strip()\n",
    "\n",
    "# Check image directory\n",
    "image_dir = \"/Users/usufahmed/Desktop/gender_app/faces/Train/\"\n",
    "if not os.path.exists(image_dir):\n",
    "    raise FileNotFoundError(f\"Directory {image_dir} does not exist.\")\n",
    "image_files = os.listdir(image_dir)\n",
    "image_bases = [os.path.splitext(f)[0].lower() for f in image_files]\n",
    "\n",
    "# Filter out IDs not found in directory\n",
    "df = df[df['ID'].isin(image_bases)]\n",
    "print(f\"Filtered dataset size: {len(df)}\")\n",
    "\n",
    "# Split dataset\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['Class'], random_state=42)\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "\n",
    "# Define image parameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Training data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load training data (use raw IDs with dynamic extension matching)\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=image_dir,\n",
    "    x_col='ID',\n",
    "    y_col='Class',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    # Dynamically append correct extension\n",
    "    x_col_modifier=lambda x: next((x + ext for ext in ['.jpg', '.jpeg', '.png'] if os.path.exists(os.path.join(image_dir, x + ext))), x + '.jpg')\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=image_dir,\n",
    "    x_col='ID',\n",
    "    y_col='Class',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    x_col_modifier=lambda x: next((x + ext for ext in ['.jpg', '.jpeg', '.png'] if os.path.exists(os.path.join(image_dir, x + ext))), x + '.jpg')\n",
    ")\n",
    "\n",
    "# Print class indices\n",
    "print(f\"Class indices: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f06c369d-9aed-4ab8-a819-e1f3246be952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset size: 19906\n",
      "Training samples: 15924\n",
      "Validation samples: 3982\n",
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Class indices: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 15924 invalid image filename(s) in x_col=\"ID\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 3982 invalid image filename(s) in x_col=\"ID\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = \"/Users/usufahmed/Desktop/gender_app/faces/train.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Check image directory\n",
    "image_dir = \"/Users/usufahmed/Desktop/gender_app/faces/Train/\"\n",
    "if not os.path.exists(image_dir):\n",
    "    raise FileNotFoundError(f\"Directory {image_dir} does not exist.\")\n",
    "image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "image_bases = [os.path.splitext(f)[0].lower() for f in image_files]\n",
    "\n",
    "# Normalize and match IDs\n",
    "df['ID'] = df['ID'].str.lower().str.replace(r'\\.jpg|\\.jpeg|\\.png', '', regex=True).str.strip()\n",
    "df = df[df['ID'].isin(image_bases)]\n",
    "print(f\"Filtered dataset size: {len(df)}\")\n",
    "\n",
    "# Split dataset\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['Class'], random_state=42)\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "\n",
    "# Define image parameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Training data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load training data with explicit filename construction\n",
    "def get_full_path(x):\n",
    "    for ext in ['.jpg', '.jpeg', '.png']:\n",
    "        full_path = os.path.join(image_dir, x + ext)\n",
    "        if os.path.exists(full_path):\n",
    "            return full_path\n",
    "    return os.path.join(image_dir, x + '.jpg')  # Default to .jpg if no match\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=image_dir,\n",
    "    x_col='ID',\n",
    "    y_col='Class',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    x_col_modifier=lambda x: get_full_path(x)\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=image_dir,\n",
    "    x_col='ID',\n",
    "    y_col='Class',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    x_col_modifier=lambda x: get_full_path(x)\n",
    ")\n",
    "\n",
    "# Print class indices\n",
    "print(f\"Class indices: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3947dc-b52b-453f-80de-53061a3abc49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
